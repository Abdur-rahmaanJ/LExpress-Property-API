import requests
import json
from bs4 import BeautifulSoup

class Agent():

    __requests_list__ = []

    def check_connection(self):
        """The internet connection to https://www.lexpressproperty.com/en/ is checked.
           Returns True if connection is successful, returns False if connection is unsuccessful."""

        try:
            server = requests.get("https://www.lexpressproperty.com/en/")
            return True
        except:
            return False

    def process_request(self, payment, property_type, sort_by):

        request_spec = {
                        "buy": {"house": {"most expensive": "HelloWorld"} "code": "B", "code": "A",
                                "villa": {"most expensive": "HelloWorld"}},
                        "rent": {},
                        "holiday": {}
                        }
        
        for payment_key in request_spec:
            if payment == payment_key:
                for property_key in request_spec[payment]:
                    if property_type == property_key:
                        for sort_by_key in request_spec[payment][property_type]:
                            if sort_by == sort_by_key:
                                print(request_spec[payment][property_type][sort_by])
                        

    def parse(self):
        pass

    def collect(self, payment = None, property_type = None, sort_by = "Least Expensive", output = False, pages = 1):

        if self.check_connection() is True:

            self.process_request(payment, property_type, sort_by)

            return None

            """# Empty list of properties is created.
            properties_list = []

            # Different URL's are generated by the Engine for the different pages of data.
            self.__requests_list__ = []
            for iteration in range(1, (pages+1)):

                # Page number is generated.
                __page_number__ = "&p=" + str(iteration)

                # URL request is created and sent.
                if valid_request is True:
                    url_request = ("https://www.lexpressproperty.com/en" + __payment__ + __property_type__ + __sort_by__ + __page_number__)
                    self.__requests_list__.append(url_request)
                    server_response = requests.get(url_request)

                    # Console output.
                    if output is True:
                        print("[" + str(server_response) + ", " + url_request + "]")

                    # Soup is created.
                    server_response = server_response.text
                    soup = BeautifulSoup(server_response, "html.parser")

                    # The soup is parsed for relevent data.
                    for html in soup.find_all("div", {"class": "text-box"}):

                        # List for the details of property is created.
                        property_list = []
                        
                        # Title is found.
                        try:
                            __title__ = html.h2.get_text().strip()
                        # The Title will be set as None if it cannot be extracted.
                        except:
                            __title__ = None

                        # The price is found.
                        try:
                            prices = html.find("strong", {"class": "price"})
                            price_one = prices.a.get_text().strip()
                            price_two = prices.em.get_text().strip()
                            __price__ = price_one + " " + price_two
                        # The price will be set as None if it cannot be extracted.
                        except:
                            __price__ = None

                        # Link is found.
                        try:
                            __link__ = html.a["href"]
                        # The link will be set as None if it cannot be extracted.
                        except:
                            __link__ = None

                        # Location is found.
                        try:
                            __location__ = html.address.get_text().strip()
                        # The location will be set as None if it cannot be extracted.
                        except:
                            __location__ = None

                        # Description is found.
                        try:
                            __description__ = html.p.get_text().strip()
                        # The description will be set as None if it cannot be extracted.
                        except:
                            __description__ = None

                        # Features of the property are found.
                        feature_list = []
                        try:
                            features = html.find("ul", {"class": "option-list"})
                            for feature in (features.find_all("li")):
                                feature_list.append(feature.get_text().strip())
                        except:
                            pass

                        # The details of the property are added to the property_list.
                        details = {"Title" : __title__, "Price" : __price__, "Location" : __location__, "Description": __description__, "URL": __link__, "Features": feature_list}
                        properties_list.append(details)

            # Retruning list is returned.
            return properties_list
    
        else:
            properties_list = []
            return properties_list

        # Console output.
        if output is True:
            print("[Termination]")
            print("")"""
